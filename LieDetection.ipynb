{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 21:36:19.832641: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn.metrics as sk\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "\n",
    "import seaborn as sns\n",
    "import helpers\n",
    "import dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lie_trial_path = './processed_lie/' #60 entries\n",
    "truth_trial_path = './processed_truth/' #61 entries\n",
    "\n",
    "MU3D_path = '/Users/frank/Downloads/dataSets/MU3D-dataset/processed/' # 320 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = dataset.path_preprocessing(truth_trial_path, lie_trial_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_RATIO = 0.2\n",
    "\n",
    "xTrain, xTest = train_test_split(X, test_size=TEST_RATIO, shuffle=False)\n",
    "yTrain, yTest = train_test_split(Y, test_size=TEST_RATIO, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1536/1536 [==============================] - 10s 5ms/step - loss: 0.6862 - accuracy: 0.5613 - val_loss: 0.6835 - val_accuracy: 0.5709\n",
      "Epoch 2/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6860 - accuracy: 0.5613 - val_loss: 0.6838 - val_accuracy: 0.5709\n",
      "Epoch 3/40\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.6858 - accuracy: 0.5613 - val_loss: 0.6837 - val_accuracy: 0.5709\n",
      "Epoch 4/40\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.6858 - accuracy: 0.5613 - val_loss: 0.6832 - val_accuracy: 0.5709\n",
      "Epoch 5/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6858 - accuracy: 0.5613 - val_loss: 0.6832 - val_accuracy: 0.5709\n",
      "Epoch 6/40\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.6858 - accuracy: 0.5613 - val_loss: 0.6832 - val_accuracy: 0.5709\n",
      "Epoch 7/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6857 - accuracy: 0.5613 - val_loss: 0.6832 - val_accuracy: 0.5709\n",
      "Epoch 8/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6856 - accuracy: 0.5613 - val_loss: 0.6831 - val_accuracy: 0.5709\n",
      "Epoch 9/40\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.6857 - accuracy: 0.5613 - val_loss: 0.6835 - val_accuracy: 0.5709\n",
      "Epoch 10/40\n",
      "1536/1536 [==============================] - 8s 6ms/step - loss: 0.6857 - accuracy: 0.5613 - val_loss: 0.6836 - val_accuracy: 0.5709\n",
      "Epoch 11/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6857 - accuracy: 0.5613 - val_loss: 0.6832 - val_accuracy: 0.5709\n",
      "Epoch 12/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6857 - accuracy: 0.5613 - val_loss: 0.6837 - val_accuracy: 0.5709\n",
      "Epoch 13/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6857 - accuracy: 0.5613 - val_loss: 0.6832 - val_accuracy: 0.5709\n",
      "Epoch 14/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6856 - accuracy: 0.5613 - val_loss: 0.6832 - val_accuracy: 0.5709\n",
      "Epoch 15/40\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.6856 - accuracy: 0.5613 - val_loss: 0.6835 - val_accuracy: 0.5709\n",
      "Epoch 16/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6857 - accuracy: 0.5613 - val_loss: 0.6834 - val_accuracy: 0.5709\n",
      "Epoch 17/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6857 - accuracy: 0.5613 - val_loss: 0.6831 - val_accuracy: 0.5709\n",
      "Epoch 18/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6856 - accuracy: 0.5613 - val_loss: 0.6834 - val_accuracy: 0.5709\n",
      "Epoch 19/40\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.6856 - accuracy: 0.5613 - val_loss: 0.6835 - val_accuracy: 0.5709\n",
      "Epoch 20/40\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.6856 - accuracy: 0.5613 - val_loss: 0.6834 - val_accuracy: 0.5709\n",
      "Epoch 21/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6855 - accuracy: 0.5613 - val_loss: 0.6832 - val_accuracy: 0.5709\n",
      "Epoch 22/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6855 - accuracy: 0.5613 - val_loss: 0.6834 - val_accuracy: 0.5709\n",
      "Epoch 23/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6855 - accuracy: 0.5613 - val_loss: 0.6831 - val_accuracy: 0.5709\n",
      "Epoch 24/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6856 - accuracy: 0.5613 - val_loss: 0.6836 - val_accuracy: 0.5709\n",
      "Epoch 25/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6855 - accuracy: 0.5613 - val_loss: 0.6831 - val_accuracy: 0.5709\n",
      "Epoch 26/40\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.6855 - accuracy: 0.5613 - val_loss: 0.6831 - val_accuracy: 0.5709\n",
      "Epoch 27/40\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.6855 - accuracy: 0.5613 - val_loss: 0.6831 - val_accuracy: 0.5709\n",
      "Epoch 28/40\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.6854 - accuracy: 0.5613 - val_loss: 0.6835 - val_accuracy: 0.5709\n",
      "Epoch 29/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6854 - accuracy: 0.5613 - val_loss: 0.6832 - val_accuracy: 0.5709\n",
      "Epoch 30/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6855 - accuracy: 0.5613 - val_loss: 0.6831 - val_accuracy: 0.5709\n",
      "Epoch 31/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6855 - accuracy: 0.5613 - val_loss: 0.6835 - val_accuracy: 0.5709\n",
      "Epoch 32/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6853 - accuracy: 0.5613 - val_loss: 0.6834 - val_accuracy: 0.5709\n",
      "Epoch 33/40\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.6855 - accuracy: 0.5613 - val_loss: 0.6836 - val_accuracy: 0.5709\n",
      "Epoch 34/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6854 - accuracy: 0.5613 - val_loss: 0.6832 - val_accuracy: 0.5709\n",
      "Epoch 35/40\n",
      "1536/1536 [==============================] - 8s 5ms/step - loss: 0.6853 - accuracy: 0.5613 - val_loss: 0.6834 - val_accuracy: 0.5709\n",
      "Epoch 36/40\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.6853 - accuracy: 0.5613 - val_loss: 0.6832 - val_accuracy: 0.5709\n",
      "Epoch 37/40\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.6854 - accuracy: 0.5613 - val_loss: 0.6834 - val_accuracy: 0.5709\n",
      "Epoch 38/40\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.6853 - accuracy: 0.5613 - val_loss: 0.6834 - val_accuracy: 0.5709\n",
      "Epoch 39/40\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.6853 - accuracy: 0.5613 - val_loss: 0.6837 - val_accuracy: 0.5709\n",
      "Epoch 40/40\n",
      "1536/1536 [==============================] - 9s 6ms/step - loss: 0.6853 - accuracy: 0.5613 - val_loss: 0.6835 - val_accuracy: 0.5709\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 125)               70500     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 125)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 252       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,755\n",
      "Trainable params: 70,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM_NEURONS = 125\n",
    "DROPOUT = 0.2\n",
    "EPOCHS = 40\n",
    "OPTIM = 'adam'\n",
    "LOSS = 'binary_crossentropy' # cross entropy/ we are doing regression, not classification!\n",
    "\n",
    "n_inputRows = xTrain.shape[0] \n",
    "n_timesteps = xTrain.shape[1]\n",
    "n_features = xTrain.shape[2]\n",
    "\n",
    "def LSTM_Model(neuro, drop, loss, optim, step, feat):\n",
    "  model = Sequential()\n",
    "  model.add(LSTM(neuro, return_sequences=False, batch_input_shape=(None, step, feat)))\n",
    "\n",
    "\n",
    "  model.add(Dropout(drop))\n",
    "  model.add(Dense(2, activation='relu')) #relu\n",
    "  model.add(Dense(1, activation='softmax')) #softmax\n",
    "  #model.add(Lambda(lambda x: tf.cast(tf.argmax(x), tf.float32)))\n",
    "  #model.add(Dense(1, activation=activ))\n",
    "\n",
    "  model.compile(loss=loss, optimizer=optim, metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "MODEL = LSTM_Model(LSTM_NEURONS, DROPOUT, LOSS, OPTIM, n_timesteps, n_features)\n",
    "\n",
    "MODEL.fit(xTrain, yTrain, validation_data=(xTest, yTest), epochs=EPOCHS, verbose=1)\n",
    "MODEL.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24b17b925cb255c3f5f9d44279af6acbce2f518dd20c49d83bc1f6775a53d6cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
