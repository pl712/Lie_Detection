{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "import glob\n",
    "import os\n",
    "import tensorflow_decision_forests as tfdf\n",
    "import sklearn.metrics as sk\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lie_trial_path = '/Users/frank/Downloads/dataSets/Trial-dataset/Clips/processed_lie/' #802 entries\n",
    "truth_trial_path = '/Users/frank/Downloads/dataSets/Trial-dataset/Clips/processed_truth/' #695 entries\n",
    "\n",
    "truth_3d_path = lie_trial_path + 'MU3D/'\n",
    "lie_3d_path = truth_trial_path + 'MU3D/'\n",
    "\n",
    "lstOfFeatures = [\"gaze_0_x\",\"gaze_0_y\",\"gaze_0_z\",\"gaze_angle_x\", \"gaze_angle_y\",\"dgaze_0_x\", \"dgaze_0_y\", \"dgaze_angle_y\", \"AU01_r\",\"AU04_r\",\"AU10_r\",\"AU12_r\",\"AU45_r\", \"pose_Tx\", \"pose_Ty\", \"pose_Tz\", \"pose_Ry\", \"Result\",\"confidence\"]\n",
    "\n",
    "# display a heatmap\n",
    "def displayHeatmap(df):\n",
    "  plt.figure(figsize=(16, 6))\n",
    "  sns.heatmap(df.corr(), vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "\n",
    "# display a confusion matrix\n",
    "def displayConfusion(actual, predicted):\n",
    "  sk.ConfusionMatrixDisplay(sk.confusion_matrix(actual, predicted)).plot()\n",
    "  print(\"Accuracy is \", round(sk.accuracy_score(actual, predicted) * 100, 2), \"%\")\n",
    "\n",
    "# remove all features not in the colList, and drop all datasets with confidence less than 0.9\n",
    "def column_and_confidence(df, colList = lstOfFeatures):\n",
    "  currdf = df\n",
    "  for col in currdf.columns:\n",
    "    if (str(col) not in colList):\n",
    "      currdf = currdf.drop(columns = [str(col)])\n",
    "  \n",
    "  currdf = currdf.query(\"confidence >= 0.9\")\n",
    "  currdf = currdf.drop(columns = [\"confidence\"])\n",
    "  currdf = currdf.dropna()\n",
    "\n",
    "  return currdf\n",
    "\n",
    "# remove all features not in the colList\n",
    "def keepColumn(df, colList = lstOfFeatures):\n",
    "  currdf = df\n",
    "  for col in currdf.columns:\n",
    "    if (str(col) not in colList):\n",
    "      currdf = currdf.drop(columns = [str(col)])\n",
    "\n",
    "  return currdf\n",
    "\n",
    "# append gaze delta to all data points with confidence more than 0.8\n",
    "def addGazeDelta(currCSV):\n",
    "  for j in range(10, currCSV.shape[0]):\n",
    "      if currCSV.iloc[[j - 10]][\"confidence\"].iloc[0] >= 0.8:\n",
    "        currCSV.at[j, 'dgaze_0_x'] = abs(currCSV.at[j - 10, 'gaze_0_x'] - currCSV.at[j, 'gaze_0_x'])\n",
    "        currCSV.at[j, 'dgaze_0_y'] = abs(currCSV.at[j - 10, 'gaze_0_y'] - currCSV.at[j, 'gaze_0_y'])\n",
    "        currCSV.at[j, 'dgaze_0_z'] = abs(currCSV.at[j - 10, 'gaze_0_z'] - currCSV.at[j, 'gaze_0_z'])\n",
    "        currCSV.at[j, 'dgaze_angle_x'] = abs(currCSV.at[j - 10, 'gaze_angle_x'] - currCSV.at[j, 'gaze_angle_x'])\n",
    "        currCSV.at[j, 'dgaze_angle_y'] = abs(currCSV.at[j - 10, 'gaze_angle_y'] - currCSV.at[j, 'gaze_angle_y'])\n",
    "\n",
    "  return currCSV\n",
    "\n",
    "# merge two dataframes without shuffle by default\n",
    "def mergeTwoDF(df1, df2, shuffle = False):\n",
    "  df = pd.concat([df1, df2]).reset_index()\n",
    "  if shuffle:\n",
    "    df = df.sample(frac=1)\n",
    "  return df\n",
    "\n",
    "# Add a result label to the datapoint with true or false (1 if true, 0 if false)\n",
    "def addLabel(df, TrueOrFalse):\n",
    "  if TrueOrFalse:\n",
    "    df[\"Result\"] = 1\n",
    "  elif not TrueOrFalse:\n",
    "    df[\"Result\"] = 0\n",
    "\n",
    "# create a single dataset from a specified path (must be all truth or all lie)\n",
    "def createDatasetSingle(path, truth):\n",
    "  df = pd.concat(map(pd.read_csv, glob.glob(os.path.join(path+\"*.csv\")))).reset_index()\n",
    "  addGazeDelta(df)\n",
    "  addLabel(df, truth)\n",
    "  df = column_and_confidence(df).reset_index().drop(columns = [\"index\"])\n",
    "\n",
    "  return df\n",
    "\n",
    "# create a dual dataset, one with truth dataset and one with false dataset, \n",
    "# then shuffle them and merge them into a single dataset\n",
    "# outputs total dataset, the data X, and a label Y\n",
    "def createDatasetDual(truthPath, liePath):\n",
    "  dfT = createDatasetSingle(truthPath, True)\n",
    "  dfL = createDatasetSingle(liePath, False)\n",
    "\n",
    "  dfTotal = mergeTwoDF(dfT, dfL, shuffle=True)\n",
    "\n",
    "  X, Y = dfTotal.drop(columns = [\"Result\"]), dfTotal[\"Result\"]\n",
    "\n",
    "  return dfTotal, X, Y\n",
    "\n",
    "# input a truthpath and a liepath, create a dual dataset and create a train\n",
    "# test split based on the testRatio\n",
    "# outputs total train, train with x, train with y, test with x, and test with y\n",
    "def createDatasetGeneral(truthPath, liePath, testRatio):\n",
    "  dfT = createDatasetSingle(truthPath, True)\n",
    "  dfL = createDatasetSingle(liePath, False)\n",
    "\n",
    "  dfTotal = mergeTwoDF(dfT, dfL, shuffle=True)\n",
    "\n",
    "  Train, Test = train_test_split(dfTotal, test_size=testRatio, shuffle=False)\n",
    "\n",
    "  Xtrain, Ytrain = Train.drop(columns = [\"Result\"]), Train[\"Result\"]\n",
    "\n",
    "  Xtest, Ytest = Test.drop(columns = [\"Result\"]), Test[\"Result\"]\n",
    "\n",
    "  return Train, Xtrain, Ytrain, Xtest, Ytest\n",
    "\n",
    "# after the model is trained, predict the video output from the path\n",
    "# use tensorflow if modelName = tf, use sklearn if modelName = sk\n",
    "# the modelObj is the training model object\n",
    "# keepList is the list of features used to predict\n",
    "# prints the possibility of lie and truth in the video\n",
    "def perdictSingleVideo(path, modelName, modelObj, keepList = lstOfFeatures):\n",
    "\n",
    "  df = pd.concat(map(pd.read_csv, glob.glob(os.path.join(path+\"*.csv\")))).reset_index()\n",
    "  addGazeDelta(df)\n",
    "  df = column_and_confidence(df).reset_index().drop(columns = [\"index\"])\n",
    "\n",
    "  counterLie, counterTrue = 0, 0\n",
    "\n",
    "  if modelName == \"tf\":\n",
    "    res = pd.DataFrame(modelObj.predict(tfdf.keras.pd_dataframe_to_tf_dataset(df)))\n",
    "\n",
    "  elif modelName == \"sk\":\n",
    "    res = modelObj.predict(df)\n",
    "    temp = res.shape[0]\n",
    "    res = pd.DataFrame(np.reshape(res, (temp, 1)))\n",
    "\n",
    "  for i in range(res.shape[0]):\n",
    "    if res.iloc[i][0] > 0.5:\n",
    "      counterTrue = counterTrue + 1\n",
    "    else:\n",
    "      counterLie = counterLie + 1\n",
    "\n",
    "  print(\"Lie Possibility: \", round(counterLie/res.shape[0] * 100, 2), \"%\")\n",
    "  print(\"Truth Possibility: \", round(counterTrue/res.shape[0]* 100, 2), \"%\")\n",
    "\n",
    "def preprocessing(folderPath, trueOrFalse, minConfidence = 0.9, numOfFrames = 10):\n",
    "  csv_files = glob.glob(os.path.join(folderPath, \"*.csv\"))\n",
    "  dropped = 0\n",
    "  processed_files = 0\n",
    "  data = []\n",
    "  label = []\n",
    "\n",
    "  # #perform normalization\n",
    "  total_csv = []\n",
    "  for file in csv_files:\n",
    "    csv_file = pd.read_csv(file)\n",
    "    csv_file = keepColumn(csv_file)\n",
    "\n",
    "    if total_csv == []:\n",
    "      total_csv = np.array(csv_file)\n",
    "    else:\n",
    "      # take out frames with confidence less than 0.9\n",
    "      for i in range(len(csv_file)):\n",
    "        if csv_file.iloc[i][\"confidence\"] <= minConfidence:\n",
    "          total_csv = np.vstack((total_csv, np.array(csv_file.iloc[i])))\n",
    "  \n",
    "  max_total = np.amax(total_csv, axis = 0)\n",
    "  print(max_total)\n",
    "\n",
    "  for file in csv_files: \n",
    "    csv_file = pd.read_csv(file)\n",
    "    csv_file = keepColumn(csv_file)\n",
    "    for i in range(csv_file.shape[0]):\n",
    "      for j in range(csv_file.shape[1]):\n",
    "        if max_total[j] != 0:\n",
    "          csv_file.iloc[i].iloc[j] = csv_file.iloc[i].iloc[j] / max_total[j]\n",
    "\n",
    "    for i in range(numOfFrames, len(csv_file)):\n",
    "      good_frame = True\n",
    "\n",
    "      # if any frame has previous frames with confidence below threhold, skip it \n",
    "      for j in range(i - numOfFrames, i):\n",
    "        if csv_file.iloc[j][\"confidence\"] <= minConfidence:\n",
    "          good_frame = False\n",
    "          dropped += 1\n",
    "          break\n",
    "\n",
    "      # if it is a good frame, let's process it \n",
    "      if not good_frame:\n",
    "        continue\n",
    "      \n",
    "      # append frames and labels to data and label array\n",
    "      data.append(csv_file.iloc[i - numOfFrames:i])\n",
    "      label.append(1) if trueOrFalse else label.append(0)\n",
    "\n",
    "  return data, label\n",
    "\n",
    "\n",
    "def path_preprocessing(truthFolderPath, lieFolderPath, minConfidence = 0.9, numOfFrames = 10):\n",
    "  truth_data, truth_label = preprocessing(truthFolderPath, True, minConfidence, numOfFrames)\n",
    "  lie_data, lie_label = preprocessing(lieFolderPath, False, minConfidence, numOfFrames) \n",
    "  \n",
    "  total_X = truth_data + lie_data\n",
    "  total_Y = truth_label + lie_label\n",
    "\n",
    "  random.seed(random.randint(1, 100))\n",
    "  random.shuffle(total_X)\n",
    "  random.shuffle(total_Y)\n",
    "\n",
    "\n",
    "  return np.array(total_X), np.array(total_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24b17b925cb255c3f5f9d44279af6acbce2f518dd20c49d83bc1f6775a53d6cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
