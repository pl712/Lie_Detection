{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 18:03:24.599457: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Embedding\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import dataset\n",
    "import test_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lie_trial_path = './processed_lie/' #60 entries\n",
    "truth_trial_path = './processed_truth/' #61 entries\n",
    "MU3D_path = './processed/' # 300 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no split by person\n",
    "numOfFrames = 10\n",
    "X, Y = dataset.preprocessing(truth_trial_path, lie_trial_path, numOfFrames=numOfFrames)\n",
    "\n",
    "TEST_RATIO = 0.2\n",
    "\n",
    "xTrain, xTest = train_test_split(X, test_size=TEST_RATIO, shuffle=False)\n",
    "yTrain, yTest = train_test_split(Y, test_size=TEST_RATIO, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5563, -0.7963, -1.0364, -0.6048],\n",
       "        [-1.8724, -0.7711,  0.3486,  1.2059],\n",
       "        [-0.5719, -0.0841, -0.7283,  0.1213],\n",
       "        [-0.1918, -0.3327,  2.5167,  0.7431],\n",
       "        [-1.0752, -0.6436, -0.8822, -2.4208],\n",
       "        [ 0.4202, -1.5169,  0.0819,  0.5593],\n",
       "        [ 2.0171, -0.4613,  1.5914,  0.2973],\n",
       "        [ 0.5733, -0.1668,  0.6712, -0.5410],\n",
       "        [-2.2083, -0.2195,  0.7277, -0.7213],\n",
       "        [-1.9518, -0.5718,  0.5207,  1.5157]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = Embedding(num_embeddings=numOfFrames, embedding_dim=4)\n",
    "\n",
    "positions = torch.tensor([0,1,2,3,4,5,6,7,8,9])\n",
    "embedded_positions = embedding_layer(positions)\n",
    "embedded_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding\n",
    "def gen_loc_list(max_frames_count, pos_encoder_size, frames_count = numOfFrames):\n",
    "  embedding = nn.Embedding(max_frames_count, pos_encoder_size)\n",
    "  input = torch.tensor([i for i in range(frames_count)]).clone().detach()\n",
    "  loc_list = embedding(input)\n",
    "\n",
    "  return loc_list\n",
    "\n",
    "def gen_data(data_arr, embedding_arr):\n",
    "\n",
    "  data_arr = torch.tensor(data_arr).clone().detach()\n",
    "  list = torch.cat((data_arr, embedding_arr), 1)\n",
    "\n",
    "  return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "  def __init__(self, inFeatCount, num_encoder_layers, n_heads = 5, n_hidden = 500, dropout = 0.3, outFeatCount = 2): #Out = [prob for 0, prob for 1]\n",
    "    super(TransformerModel, self).__init__()\n",
    "\n",
    "    encoder_layer = TransformerEncoderLayer(inFeatCount, n_heads, n_hidden, dropout)\n",
    "\n",
    "    self.encoder = TransformerEncoder(encoder_layer, num_encoder_layers)\n",
    "\n",
    "    self.decoder = nn.Linear(inFeatCount, outFeatCount)\n",
    "\n",
    "  def init_weights(self):\n",
    "      initrange = 0.1\n",
    "      self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "      self.decoder.bias.data.zero_()\n",
    "      self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "  def forward(self, data):\n",
    "      encoded = self.encoder(data)\n",
    "      output = self.decoder(encoded)\n",
    "      return torch.nn.functional.softmax(output)\n",
    "  \n",
    "def predict(model, inputArr):\n",
    "    inputArr = inputArr.to(device).float()\n",
    "    \n",
    "    output = model(inputArr)\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_encoder_size = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate embedding\n",
    "embedding_arr = gen_loc_list(numOfFrames, pos_encoder_size)\n",
    "\n",
    "#generate embedded data\n",
    "x_Train = []\n",
    "x_Test = []\n",
    "\n",
    "y_Train = []\n",
    "y_Test = []\n",
    "\n",
    "for i in range(xTrain.shape[0]):\n",
    "    x_Train.append(gen_data(xTrain[i], embedding_arr).detach().numpy())\n",
    "\n",
    "for i in range(xTest.shape[0]):\n",
    "    x_Test.append(gen_data(xTest[i], embedding_arr).detach().numpy())\n",
    "\n",
    "for i in range(yTrain.shape[0]):\n",
    "    if yTrain[i] == 0:\n",
    "        y_Train.append([[1,0],[1,0],[1,0],[1,0],[1,0],[1,0],[1,0],[1,0],[1,0],[1,0]])\n",
    "    else:\n",
    "        y_Train.append([[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[0,1]])\n",
    "\n",
    "for i in range(yTest.shape[0]):\n",
    "    if yTest[i] == 0:\n",
    "        y_Test.append([[1,0],[1,0],[1,0],[1,0],[1,0],[1,0],[1,0],[1,0],[1,0],[1,0]])\n",
    "    else:\n",
    "        y_Test.append([[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[0,1],[0,1]])\n",
    "\n",
    "#generate model\n",
    "model = TransformerModel(15, 5).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/66/pn8653k51_75x5ksbpsy8hm80000gn/T/ipykernel_22055/476567611.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return torch.nn.functional.softmax(output)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8) must match the size of tensor b (10) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/frank/Downloads/Projects/Lie Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 88>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/frank/Downloads/Projects/Lie%20Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb#X12sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m, Loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Accuracy: \u001b[39m\u001b[39m{\u001b[39;00macc\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Test Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mtest_acc\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/frank/Downloads/Projects/Lie%20Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb#X12sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m         idx \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/frank/Downloads/Projects/Lie%20Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb#X12sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m train(model, x_Train, y_Train, x_Test, y_Test)\n",
      "\u001b[1;32m/Users/frank/Downloads/Projects/Lie Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb Cell 10\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, xTrain, yTrain, xTest, yTest, epochs, lr, batch_size)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/frank/Downloads/Projects/Lie%20Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb#X12sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     y_test \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(yTest[idx])\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/frank/Downloads/Projects/Lie%20Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb#X12sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     \u001b[39m# compute test accuracy\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/frank/Downloads/Projects/Lie%20Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb#X12sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m     test_acc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (y_pred\u001b[39m.\u001b[39;49margmax(\u001b[39m1\u001b[39;49m) \u001b[39m==\u001b[39;49m y_test)\u001b[39m.\u001b[39mtype(torch\u001b[39m.\u001b[39mfloat)\u001b[39m.\u001b[39mmean()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/frank/Downloads/Projects/Lie%20Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb#X12sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m test_acc \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(xTest_loader)  \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/frank/Downloads/Projects/Lie%20Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb#X12sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m test_accuracy_items\u001b[39m.\u001b[39mappend(test_acc)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (8) must match the size of tensor b (10) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "# training\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def train(model, xTrain, yTrain, xTest, yTest, epochs = 100, lr = 0.001, batch_size = 10):\n",
    "    \"\"\" Train a model on a dataset \"\"\"\n",
    "\n",
    "    loss_items = []\n",
    "    accuracy_items = []\n",
    "    test_accuracy_items = []\n",
    "    \n",
    "    # create a data loader to handle batching\n",
    "    xTrain_loader =  torch.utils.data.DataLoader(xTrain, batch_size=batch_size, shuffle=False)\n",
    "    xTest_loader = torch.utils.data.DataLoader(xTest, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # create a loss function and optimizer\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # train the model\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # train\n",
    "\n",
    "        idx = 0\n",
    "        model.train()\n",
    "        for batch in xTrain_loader:\n",
    "\n",
    "            # get data\n",
    "            x_train = batch.to(device).float()\n",
    "            y_train = torch.tensor(yTrain[idx]).to(device)\n",
    "\n",
    "            # forward pass\n",
    "            y_pred = model(x_train)\n",
    "\n",
    "            # compute loss\n",
    "            loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # update weights\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # evaluate\n",
    "        model.eval()\n",
    "\n",
    "        test_acc = 0\n",
    "        acc = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            idx_test = 0\n",
    "            for batch in xTest_loader:\n",
    "                xTest = batch.to(device).float()\n",
    "                y_pred = model(xTest)\n",
    "                y_test = torch.tensor(yTest[idx_test]).to(device)\n",
    "\n",
    "                # compute test accuracy\n",
    "                test_acc += (y_pred.argmax(1) == y_test).type(torch.float).mean().item()\n",
    "                idx_test += 1\n",
    "                \n",
    "\n",
    "            test_acc / len(xTest_loader)  \n",
    "            test_accuracy_items.append(test_acc)\n",
    "\n",
    "            idx_train = 0\n",
    "            for batch in xTrain_loader:\n",
    "                xTrain = batch.to(device).float()\n",
    "                y_pred = model(xTrain)\n",
    "                y_train = torch.tensor(yTrain[idx_train]).to(device)\n",
    "\n",
    "                # compute accuracy\n",
    "                acc += (y_pred.argmax(1) == y_train).type(torch.float).mean().item()\n",
    "                idx_train += 1\n",
    "\n",
    "            acc / len(xTrain_loader)\n",
    "            accuracy_items.append(acc)\n",
    "\n",
    "        # store loss and accuracy\n",
    "        loss_items.append(loss.item())\n",
    "\n",
    "        # print progress\n",
    "        if (epoch+1) % 1 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}, Accuracy: {acc:.4f}, Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "        idx += 1\n",
    "            \n",
    "\n",
    "train(model, x_Train, y_Train, x_Test, y_Test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "24b17b925cb255c3f5f9d44279af6acbce2f518dd20c49d83bc1f6775a53d6cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
