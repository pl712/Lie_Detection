{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-08 14:30:20.721613: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Embedding\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import dataset\n",
    "import test_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lie_trial_path = './processed_lie/' #60 entries\n",
    "truth_trial_path = './processed_truth/' #61 entries\n",
    "MU3D_path = './processed/' # 300 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no split by person\n",
    "X, Y = dataset.preprocessing(truth_trial_path, lie_trial_path, numOfFrames=10)\n",
    "\n",
    "TEST_RATIO = 0.2\n",
    "\n",
    "xTrain, xTest = train_test_split(X, test_size=TEST_RATIO, shuffle=False)\n",
    "yTrain, yTest = train_test_split(Y, test_size=TEST_RATIO, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.5237e-01,  1.5675e-01,  4.2209e-01,  3.1437e-01],\n",
       "        [-1.9194e+00, -1.1530e+00, -2.5596e-01, -6.6277e-01],\n",
       "        [ 1.1716e-02,  9.7424e-01, -3.3911e-01, -6.4918e-01],\n",
       "        [-7.5915e-01,  3.4919e-01, -4.4198e-01,  5.2211e-01],\n",
       "        [ 7.0474e-01, -1.4141e+00, -9.7262e-01, -1.9992e-01],\n",
       "        [ 2.3989e-01,  3.0762e-04,  3.2785e-01,  1.0899e+00],\n",
       "        [ 5.4010e-02, -1.9672e+00, -8.0634e-01, -3.2001e-01],\n",
       "        [-7.5895e-01, -7.3678e-01, -1.8904e+00,  1.2929e-01],\n",
       "        [-1.6781e+00,  7.3380e-01, -1.0691e-01,  2.7702e-01],\n",
       "        [ 2.4964e-01, -1.2619e+00,  1.0165e+00, -1.5233e+00]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = Embedding(num_embeddings=10, embedding_dim=4)\n",
    "\n",
    "positions = torch.tensor([0,1,2,3,4,5,6,7,8,9])\n",
    "embedded_positions = embedding_layer(positions)\n",
    "embedded_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3846,  0.2573, -0.8865,  0.3230,  0.2880,  0.2500,  0.1300,  1.7700,\n",
       "          0.0000,  0.1600,  0.3792, -0.1752, -0.3183,  1.9539],\n",
       "        [ 0.3859,  0.2574, -0.8859,  0.3240,  0.2890,  0.1500,  0.0600,  1.7500,\n",
       "          0.0000,  0.2400,  0.2904,  0.0217, -0.1931, -0.1589],\n",
       "        [ 0.3864,  0.2583, -0.8854,  0.3250,  0.2900,  0.1400,  0.0700,  1.7300,\n",
       "          0.0000,  0.2600, -0.4204,  0.4735,  0.3364, -0.8281],\n",
       "        [ 0.3874,  0.2542, -0.8862,  0.3260,  0.2850,  0.1600,  0.1000,  1.8200,\n",
       "          0.0000,  0.2100, -0.4550, -0.1587, -0.1849,  0.1962],\n",
       "        [ 0.3835,  0.2552, -0.8876,  0.3230,  0.2860,  0.1500,  0.1100,  1.9200,\n",
       "          0.0000,  0.2500,  0.2708, -0.5133,  1.4081, -1.7879],\n",
       "        [ 0.3830,  0.2547, -0.8879,  0.3230,  0.2850,  0.1200,  0.1100,  1.9700,\n",
       "          0.0000,  0.1600, -0.0289,  0.8875, -1.3817, -0.5853],\n",
       "        [ 0.3842,  0.2522, -0.8881,  0.3240,  0.2820,  0.0600,  0.1200,  2.0400,\n",
       "          0.0000,  0.1100,  1.3679,  0.3769,  0.1092,  0.1507],\n",
       "        [ 0.3838,  0.2492, -0.8891,  0.3230,  0.2790,  0.0500,  0.1700,  2.0300,\n",
       "          0.0000,  0.0000, -1.4515, -1.1667, -0.4252,  0.0133],\n",
       "        [ 0.3792,  0.2463, -0.8919,  0.3180,  0.2740,  0.0100,  0.2000,  2.0600,\n",
       "          0.0000,  0.0000,  0.8951, -1.8681, -1.2791,  1.0614],\n",
       "        [ 0.3814,  0.2481, -0.8905,  0.3200,  0.2770,  0.0100,  0.2000,  1.9500,\n",
       "          0.0000,  0.0000, -1.6353,  1.2068,  0.4600, -0.5375]],\n",
       "       dtype=torch.float64, grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embedding\n",
    "def gen_loc_list(max_frames_count, pos_encoder_size, frames_count = 10):\n",
    "  embedding = nn.Embedding(max_frames_count, pos_encoder_size)\n",
    "  input = torch.tensor([i for i in range(frames_count)]).clone().detach()\n",
    "  loc_list = embedding(input)\n",
    "\n",
    "  return loc_list\n",
    "\n",
    "def gen_data(data_arr, embedding_arr):\n",
    "\n",
    "  data_arr = torch.tensor(data_arr).clone().detach()\n",
    "  list = torch.cat((data_arr, embedding_arr), 1)\n",
    "\n",
    "  return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "  def __init__(self, inFeatCount, num_encoder_layers, n_heads = 5, n_hidden = 500, dropout = 0.3, outFeatCount = 2): #Out = [prob for 0, prob for 1]\n",
    "    super(TransformerModel, self).__init__()\n",
    "\n",
    "    encoder_layer = TransformerEncoderLayer(inFeatCount, n_heads, n_hidden, dropout)\n",
    "\n",
    "    self.encoder = TransformerEncoder(encoder_layer, num_encoder_layers)\n",
    "\n",
    "    self.decoder = nn.Linear(inFeatCount, outFeatCount)\n",
    "\n",
    "  def init_weights(self):\n",
    "      initrange = 0.1\n",
    "      self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "      self.decoder.bias.data.zero_()\n",
    "      self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "  def forward(self, data):\n",
    "      encoded = self.encoder(data)\n",
    "      output = self.decoder(encoded)\n",
    "      return torch.nn.functional.softmax(output)\n",
    "  \n",
    "def predict(model, inputArr):\n",
    "    inputArr = inputArr.to(device).float()\n",
    "    \n",
    "    output = model(inputArr)\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_frames_count = 20\n",
    "pos_encoder_size = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3094, 0.3626, 0.5688, 0.3559, 0.5062, 0.1966, 0.3175, 0.7242, 0.4109,\n",
      "        0.3316], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/66/pn8653k51_75x5ksbpsy8hm80000gn/T/ipykernel_3536/6805551.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return torch.nn.functional.softmax(output)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([])) that is different to the input size (torch.Size([10])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/frank/Downloads/Projects/Lie Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/frank/Downloads/Projects/Lie%20Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mBCELoss()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/frank/Downloads/Projects/Lie%20Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(predict(model, data)[:,\u001b[39m0\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/frank/Downloads/Projects/Lie%20Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(criterion(predict(model, data)[:,\u001b[39m0\u001b[39;49m], torch\u001b[39m.\u001b[39;49mtensor(yTrain[\u001b[39m0\u001b[39;49m])))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:612\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 612\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:3056\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3054\u001b[0m     reduction_enum \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3055\u001b[0m \u001b[39mif\u001b[39;00m target\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize():\n\u001b[0;32m-> 3056\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   3057\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing a target size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) that is different to the input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) is deprecated. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3058\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure they have the same size.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m   3059\u001b[0m     )\n\u001b[1;32m   3061\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3062\u001b[0m     new_size \u001b[39m=\u001b[39m _infer_size(target\u001b[39m.\u001b[39msize(), weight\u001b[39m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([])) that is different to the input size (torch.Size([10])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "#generate embedding\n",
    "embedding_arr = gen_loc_list(max_frames_count, pos_encoder_size)\n",
    "\n",
    "#generate embedded data\n",
    "data = gen_data(xTrain[0], embedding_arr)\n",
    "\n",
    "#generate model\n",
    "model = TransformerModel(15, 5)\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "print(predict(model, data)[:,0])\n",
    "print(criterion(predict(model, data)[:,0], torch.tensor(yTrain[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/66/pn8653k51_75x5ksbpsy8hm80000gn/T/ipykernel_3536/6805551.py:25: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return torch.nn.functional.softmax(output)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([])) that is different to the input size (torch.Size([2])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/frank/Downloads/Projects/Lie Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/frank/Downloads/Projects/Lie%20Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb#X15sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/frank/Downloads/Projects/Lie%20Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb#X15sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m train_losses, test_losses, train_acc, test_acc\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/frank/Downloads/Projects/Lie%20Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m train(model, xTrain, yTrain, xTest, yTest)\n",
      "\u001b[1;32m/Users/frank/Downloads/Projects/Lie Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb Cell 10\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, xTrain, yTrain, xTest, yTest, epochs, lr, batch_size)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/frank/Downloads/Projects/Lie%20Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/frank/Downloads/Projects/Lie%20Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m result \u001b[39m=\u001b[39m predict(model, gen_data(xTrain[\u001b[39m0\u001b[39m], embedding_arr))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/frank/Downloads/Projects/Lie%20Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(result[\u001b[39m0\u001b[39;49m,:], torch\u001b[39m.\u001b[39;49mtensor(yTrain[\u001b[39m0\u001b[39;49m]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/frank/Downloads/Projects/Lie%20Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m#loss.backward()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/frank/Downloads/Projects/Lie%20Detection/Lie_Detection/LieDetection_transformer_deprecated.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:612\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 612\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mbinary_cross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:3056\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3054\u001b[0m     reduction_enum \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3055\u001b[0m \u001b[39mif\u001b[39;00m target\u001b[39m.\u001b[39msize() \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize():\n\u001b[0;32m-> 3056\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   3057\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing a target size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) that is different to the input size (\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m) is deprecated. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3058\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease ensure they have the same size.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(target\u001b[39m.\u001b[39msize(), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize())\n\u001b[1;32m   3059\u001b[0m     )\n\u001b[1;32m   3061\u001b[0m \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3062\u001b[0m     new_size \u001b[39m=\u001b[39m _infer_size(target\u001b[39m.\u001b[39msize(), weight\u001b[39m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([])) that is different to the input size (torch.Size([2])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "# training\n",
    "import torch.optim as optim\n",
    "\n",
    "def train(model, xTrain, yTrain, xTest, yTest, epochs = 100, lr = 0.001, batch_size = 32):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    result = predict(model, gen_data(xTrain[0], embedding_arr))\n",
    "    loss = criterion(result[0,:], torch.tensor(yTrain[0]))\n",
    "    #loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "        \n",
    "    \n",
    "    return train_losses, test_losses, train_acc, test_acc\n",
    "\n",
    "train(model, xTrain, yTrain, xTest, yTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "24b17b925cb255c3f5f9d44279af6acbce2f518dd20c49d83bc1f6775a53d6cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
